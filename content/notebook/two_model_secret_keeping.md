+++
title="Can language models keep a secret"
date=2024-08-27
+++

Maybe? Check it out [here](https://github.com/skunnavakkam/two-model-redteaming)

One model, as a prompter, gives another model a secret to keep, and this keeps improving as the prompter realizes what the failure modes of the guard model are. The big determiner of anything is the intelligence of the guard model unfortunately :c